{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1OQnfkBTOh7KiguJq1WcrpmQwGA3EMUtA",
      "authorship_tag": "ABX9TyNIIXRcgL0wT35ZIMZ2i/wc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alvaroguarda/cats-dogs/blob/main/SistemaReconhecimentoFacial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mtcnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fNi_vWrYcMMd",
        "outputId": "de122d78-d2b0-4f1d-c434-1a88f944a96c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mtcnn\n",
            "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from mtcnn) (1.5.2)\n",
            "Collecting lz4>=4.3.3 (from mtcnn)\n",
            "  Downloading lz4-4.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Downloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lz4, mtcnn\n",
            "Successfully installed lz4-4.4.4 mtcnn-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Syrw5zGPcnrF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mtcnn.mtcnn import MTCNN\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "g_fh_HIgb93W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "TQiM_jzZerXe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector = MTCNN()"
      ],
      "metadata": {
        "id": "Ca1QQ5pabzNm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display image\n",
        "def display(img, neww, frameName=\"Image\"):\n",
        "    h, w = img.shape[0:2]\n",
        "    newh = int(neww*(h/w))\n",
        "    img = cv2.resize(img, (neww, newh))\n",
        "    cv2.imshow(frameName, img)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "TDxUooonfkCD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to detect faces in an image\n",
        "def detect_faces(image_path):\n",
        "    \"\"\"\n",
        "    Detects faces in an image and draws rectangles around them.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the image file.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray or None: The image with rectangles drawn around faces,\n",
        "                                 or None if the image could not be read.\n",
        "        list: List of detected face coordinates. Element: [x, y, w, h].\n",
        "    \"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    if img is None:\n",
        "        print(f\"Error: Could not read image file {image_path}\")\n",
        "        return None\n",
        "\n",
        "    # Detect faces in the image\n",
        "    faces_rect = detector.detect_faces(img)\n",
        "\n",
        "    return img, faces_rect"
      ],
      "metadata": {
        "id": "PO6Qp7Zubyc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "def learn(data_path):\n",
        "    # Define image size, batch size, and other parameters\n",
        "    img_size = (224, 224)\n",
        "    batch_size = 32\n",
        "    num_classes = 4  # Number of classes in the dataset\n",
        "    epochs = 20\n",
        "    learning_rate = 0.0001\n",
        "    input_shape = (224, 224, 3)\n",
        "    validation_split = 0.2\n",
        "\n",
        "    # Load the VGG16 model without the top layers and with pre-trained weights\n",
        "    base_model = VGG16(weights='imagenet', include_top=False,\n",
        "                       input_shape=input_shape, pooling='max')\n",
        "    base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "    # Create a new model and add layers\n",
        "    model = Sequential()\n",
        "    model.add(base_model)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    # Compile the model\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Print the model summary\n",
        "    model.summary()\n",
        "\n",
        "    # Data augmentation and data generators\n",
        "    datagen = ImageDataGenerator(rescale=1./255, validation_split=validation_split)\n",
        "    train_generator = datagen.flow_from_directory(data_path, target_size=img_size, batch_size=batch_size, class_mode='sparse', subset='training')\n",
        "    validation_generator = datagen.flow_from_directory(data_path, target_size=img_size, batch_size=batch_size, class_mode='sparse', subset='validation')\n",
        "\n",
        "    class_name_list = list(train_generator.class_indices.keys())\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(train_generator, epochs=epochs, validation_data=validation_generator)\n",
        "    # Save the trained model\n",
        "    model.save('VGG16_finetuned_model.h5')\n",
        "    print('Model trained and saved as vgg16_finetuned_model.h5')\n",
        "    return model, history, img_size, class_name_list\n"
      ],
      "metadata": {
        "id": "Q_Gh3AAvm3-l"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the learning history\n",
        "def plot_history(history):\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    # Plot training & validation loss values\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.show()\n",
        "    return"
      ],
      "metadata": {
        "id": "-1xDykgKoTKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess and predict the class of a new image\n",
        "def predict_image(img, model, img_size):\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, img_size)\n",
        "    img = img.astype('float32') / 255.0\n",
        "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "    predictions = model.predict(img)\n",
        "    print(predictions)\n",
        "    predicted_class = np.argmax(predictions, axis=1)[0]\n",
        "    confidence = np.max(predictions)\n",
        "    return predicted_class, confidence"
      ],
      "metadata": {
        "id": "AEOi5gV0paR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the learn function\n",
        "data_path = 'images/Cleaned Dataset'\n",
        "\n",
        "# Train the model\n",
        "model, history, img_size, class_name_list = learn(data_path)\n",
        "# Plot training history\n",
        "plot_history(history)"
      ],
      "metadata": {
        "id": "rGxTrLOVoAnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage of the face detection function\n",
        "test_image_path = 'C:/FaceRecognition/images/teste_612x612.jpg'\n",
        "\n",
        "if os.path.exists(test_image_path):\n",
        "    img, faces_rect = detect_faces(test_image_path)\n",
        "\n",
        "    # Predict end draw rectangles around the detected faces\n",
        "    #for (x, y, w, h) in faces_rect:\n",
        "    for result in faces_rect:\n",
        "        x, y, w, h = result['box']\n",
        "        face_img = img[y:y+h, x:x+w]\n",
        "        predicted_class, confidence = predict_image(face_img, model, img_size)\n",
        "        confidence = int(confidence * 100)  # Convert to percentage\n",
        "        print(f'Predicted class: {class_name_list[predicted_class]}, Confidence: {confidence}', '%')\n",
        "\n",
        "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2) # Blue rectangle\n",
        "        # Add class label and confidence\n",
        "        label = f\"{class_name_list[predicted_class]}: {confidence}%\"\n",
        "        if confidence < 50:\n",
        "            label = f\"Unknown : {confidence}\"\n",
        "        cv2.putText(\n",
        "            img,\n",
        "            text=label,\n",
        "            org=(x, max(y-10, 0)),\n",
        "            fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
        "            fontScale=0.3,\n",
        "            color=(36, 255, 12),\n",
        "            thickness=1\n",
        "        )  # Green text\n",
        "\n",
        "    # Display the image with detected faces\n",
        "    display(img, 600, \"Detected Faces\")\n",
        "else:\n",
        "    print(f'Test image not found at {test_image_path}. Please provide a valid image path.')"
      ],
      "metadata": {
        "id": "ceRT0mzipQLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------"
      ],
      "metadata": {
        "id": "wofMSTt_aZkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image(path):\n",
        "    try:\n",
        "        if os.path.getsize(path) > 0: # Check if file is not empty\n",
        "          img = image.load_img(path, target_size=(224, 224))\n",
        "          x = image.img_to_array(img)\n",
        "          x = np.expand_dims(x, axis=0)\n",
        "          x = preprocess_input(x)\n",
        "          return img, x\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading image {path}: {e}\")\n",
        "    return None, None"
      ],
      "metadata": {
        "id": "rlOHYSrxXrMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUZnPEi2VmjL"
      },
      "outputs": [],
      "source": [
        "img_path = 'FaceRecognition/images/homem/frame_0000.jpg'\n",
        "\n",
        "img, x = get_image(img_path)\n",
        "\n",
        "# load image from file\n",
        "pixels = plt.imread(img_path)\n",
        "\n",
        "# create the detector, using default weights\n",
        "detector = MTCNN()\n",
        "# detect faces in the image\n",
        "results = detector.detect_faces(pixels)\n",
        "\n",
        "# # display faces on the original image\n",
        "# fig, ax = plt.subplots(figsize=(10, 10))\n",
        "# ax.imshow(pixels)\n",
        "# # plot each box\n",
        "# for result in results:\n",
        "#     x, y, width, height = result['box']\n",
        "#     # create the shape\n",
        "#     rect = patches.Rectangle((x, y), width, height, fill=False, color='red')\n",
        "#     ax.add_patch(rect)\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# extract the bounding box from the first face\n",
        "x1, y1, width, height = results[0]['box']\n",
        "x2, y2 = x1 + width, y1 + height\n",
        "\n",
        "# extract the face\n",
        "face = pixels[y1:y2, x1:x2]\n",
        "# resize pixels to the model size\n",
        "image = Image.fromarray(face)\n",
        "image = image.resize((224, 224))\n",
        "face_array = np.asarray(image)\n",
        "\n",
        "\n",
        "# extract a single face from a given photograph\n",
        "def extract_face(filename, required_size=(224, 224)):\n",
        "\t# load image from file\n",
        "    pixels = plt.imread(img_path)\n",
        "    # create the detector, using default weights\n",
        "    detector = MTCNN()\n",
        "\t# detect faces in the image\n",
        "    results = detector.detect_faces(pixels)\n",
        "\t# extract the bounding box from the first face\n",
        "    x1, y1, width, height = results[0]['box']\n",
        "    x2, y2 = x1 + width, y1 + height\n",
        "\t# extract the face\n",
        "    face = pixels[y1:y2, x1:x2]\n",
        "\t# resize pixels to the model size\n",
        "    image = Image.fromarray(face)\n",
        "    image = image.resize(required_size)\n",
        "    face_array = np.asarray(image)\n",
        "    return face_array\n",
        "\n",
        "# load the photo and extract the face\n",
        "pixels = extract_face(img_path)\n",
        "# convert one face into samples\n",
        "pixels = pixels.astype('float32')\n",
        "samples = expand_dims(pixels, axis=0)\n",
        "# prepare the face for the model, e.g. center pixels\n",
        "samples = preprocess_input(samples, version=2)\n",
        "# create a vggface model\n",
        "model = VGGFace(model='resnet50')\n",
        "# perform prediction\n",
        "yhat = model.predict(samples)\n",
        "# convert prediction into names\n",
        "results = decode_predictions(yhat)\n",
        "# display most likely results\n",
        "for result in results[0]:\n",
        "\tprint('%s: %.3f%%' % (result[0], result[1]*100))\n"
      ]
    }
  ]
}